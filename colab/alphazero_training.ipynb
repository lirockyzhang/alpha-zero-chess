{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlphaZero Chess Training on Google Colab\n",
    "\n",
    "Train an AlphaZero chess engine using a C++ MCTS backend with GPU-accelerated neural networks.\n",
    "\n",
    "**Requirements:**\n",
    "- Colab GPU runtime (Runtime \u2192 Change runtime type \u2192 T4 GPU)\n",
    "- Google Drive for persistent checkpoint storage\n",
    "\n",
    "**What this notebook does:**\n",
    "1. Builds the C++ backend (MCTS + self-play engine) from source\n",
    "2. Runs the AlphaZero training loop with parallel self-play\n",
    "3. Saves checkpoints to Google Drive so they persist across sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. GPU Check & Google Drive Mount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify GPU is available and mount Google Drive for checkpoint persistence\n",
    "import torch\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    raise RuntimeError(\n",
    "        \"No GPU detected! Go to Runtime > Change runtime type > T4 GPU\"\n",
    "    )\n",
    "\n",
    "print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"CUDA: {torch.version.cuda}\")\n",
    "!nvidia-smi --query-gpu=name,memory.total --format=csv,noheader\n",
    "\n",
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")\n",
    "\n",
    "import os\n",
    "DRIVE_DIR = \"/content/drive/MyDrive/alphazero-chess\"\n",
    "os.makedirs(DRIVE_DIR, exist_ok=True)\n",
    "print(f\"\\nDrive output directory: {DRIVE_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Clone Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "REPO_DIR = \"/content/alpha-zero-chess\"\n",
    "\n",
    "if not os.path.exists(REPO_DIR):\n",
    "    !git clone https://github.com/lirockyzhang/alpha-zero-chess.git {REPO_DIR}\n",
    "else:\n",
    "    print(f\"Repository already cloned at {REPO_DIR}\")\n",
    "    !cd {REPO_DIR} && git pull\n",
    "\n",
    "os.chdir(REPO_DIR)\n",
    "print(f\"Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch and numpy are pre-installed on Colab\n",
    "# We only need pybind11 (for building C++) and python-chess (for the training script)\n",
    "!pip install pybind11 python-chess -q\n",
    "\n",
    "# Verify imports\n",
    "import pybind11, chess, torch, numpy\n",
    "print(f\"pybind11:     {pybind11.__version__}\")\n",
    "print(f\"python-chess: {chess.__version__}\")\n",
    "print(f\"torch:        {torch.__version__}\")\n",
    "print(f\"numpy:        {numpy.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Build C++ Module\n",
    "\n",
    "Compiles the C++ MCTS engine and Python bindings. This takes ~2 minutes on Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, subprocess\n",
    "\n",
    "BUILD_DIR = os.path.join(REPO_DIR, \"alphazero-cpp\", \"build\")\n",
    "os.makedirs(BUILD_DIR, exist_ok=True)\n",
    "\n",
    "# Get pybind11 cmake directory (overrides the hardcoded Windows path in CMakeLists.txt)\n",
    "pybind11_dir = subprocess.check_output(\n",
    "    [\"python3\", \"-c\", \"import pybind11; print(pybind11.get_cmake_dir())\"]\n",
    ").decode().strip()\n",
    "print(f\"pybind11 cmake dir: {pybind11_dir}\")\n",
    "\n",
    "# Configure\n",
    "!cd {BUILD_DIR} && cmake .. \\\n",
    "    -DCMAKE_BUILD_TYPE=Release \\\n",
    "    -Dpybind11_DIR=\"{pybind11_dir}\"\n",
    "\n",
    "# Build using all available cores\n",
    "import multiprocessing\n",
    "n_cores = multiprocessing.cpu_count()\n",
    "print(f\"\\nBuilding with {n_cores} cores...\")\n",
    "!cd {BUILD_DIR} && cmake --build . --config Release -j{n_cores}\n",
    "\n",
    "# On Linux, CMake puts the .so directly in build/ (not build/Release/)\n",
    "# The training script expects it in build/Release/, so create that structure\n",
    "RELEASE_DIR = os.path.join(BUILD_DIR, \"Release\")\n",
    "os.makedirs(RELEASE_DIR, exist_ok=True)\n",
    "\n",
    "import glob\n",
    "so_files = glob.glob(os.path.join(BUILD_DIR, \"alphazero_cpp*.so\"))\n",
    "if so_files:\n",
    "    for so in so_files:\n",
    "        target = os.path.join(RELEASE_DIR, os.path.basename(so))\n",
    "        if not os.path.exists(target):\n",
    "            os.symlink(so, target)\n",
    "            print(f\"Symlinked: {os.path.basename(so)} -> Release/\")\n",
    "\n",
    "# Verify the module loads\n",
    "import sys\n",
    "sys.path.insert(0, RELEASE_DIR)\n",
    "sys.path.insert(0, BUILD_DIR)\n",
    "import alphazero_cpp\n",
    "print(f\"\\nalphazero_cpp loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Configure Training Parameters\n",
    "\n",
    "Adjust these parameters before starting training. The defaults are a good starting point for full training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Training Configuration { run: \"auto\" }\n",
    "\n",
    "# --- Network Architecture ---\n",
    "FILTERS = 192          # @param {type: \"integer\"}\n",
    "BLOCKS = 15            # @param {type: \"integer\"}\n",
    "\n",
    "# --- Training Loop ---\n",
    "ITERATIONS = 100       # @param {type: \"integer\"}\n",
    "GAMES_PER_ITER = 50    # @param {type: \"integer\"}\n",
    "SIMULATIONS = 800      # @param {type: \"integer\"}\n",
    "EPOCHS = 5             # @param {type: \"integer\"}\n",
    "LR = 0.001             # @param {type: \"number\"}\n",
    "TRAIN_BATCH = 256      # @param {type: \"integer\"}\n",
    "BUFFER_SIZE = 100000   # @param {type: \"integer\"}\n",
    "\n",
    "# --- Parallel Self-Play ---\n",
    "WORKERS = 16           # @param {type: \"integer\"}\n",
    "EVAL_BATCH = 512       # @param {type: \"integer\"}\n",
    "\n",
    "# --- Checkpointing ---\n",
    "SAVE_INTERVAL = 5      # @param {type: \"integer\"}\n",
    "\n",
    "# --- Resume from previous run (leave empty for fresh start) ---\n",
    "RESUME_PATH = \"\"       # @param {type: \"string\"}\n",
    "\n",
    "# --- Checkpoint directory setup ---\n",
    "import os\n",
    "\n",
    "SAVE_DIR = os.path.join(DRIVE_DIR, \"checkpoints\")\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# Create symlink so the training script's default path also works\n",
    "LOCAL_CKPT = os.path.join(REPO_DIR, \"checkpoints\")\n",
    "if os.path.islink(LOCAL_CKPT):\n",
    "    os.remove(LOCAL_CKPT)\n",
    "if not os.path.exists(LOCAL_CKPT):\n",
    "    os.symlink(SAVE_DIR, LOCAL_CKPT)\n",
    "    print(f\"Symlinked checkpoints/ -> {SAVE_DIR}\")\n",
    "else:\n",
    "    print(f\"Note: {LOCAL_CKPT} already exists as a directory, using --save-dir instead\")\n",
    "\n",
    "print(f\"\\nCheckpoints will be saved to: {SAVE_DIR}\")\n",
    "print(f\"Network: {FILTERS} filters, {BLOCKS} blocks\")\n",
    "print(f\"Training: {ITERATIONS} iterations, {GAMES_PER_ITER} games/iter, {WORKERS} workers\")\n",
    "if RESUME_PATH:\n",
    "    print(f\"Resuming from: {RESUME_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Run Training\n",
    "\n",
    "This starts the AlphaZero training loop. Progress is printed every 30 seconds.\n",
    "\n",
    "Checkpoints are saved to Google Drive every `SAVE_INTERVAL` iterations, so they persist even if Colab disconnects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "cmd = (\n",
    "    f\"python {os.path.join(REPO_DIR, 'alphazero-cpp', 'scripts', 'train.py')}\"\n",
    "    f\" --iterations {ITERATIONS}\"\n",
    "    f\" --games-per-iter {GAMES_PER_ITER}\"\n",
    "    f\" --simulations {SIMULATIONS}\"\n",
    "    f\" --workers {WORKERS}\"\n",
    "    f\" --eval-batch {EVAL_BATCH}\"\n",
    "    f\" --filters {FILTERS}\"\n",
    "    f\" --blocks {BLOCKS}\"\n",
    "    f\" --train-batch {TRAIN_BATCH}\"\n",
    "    f\" --lr {LR}\"\n",
    "    f\" --epochs {EPOCHS}\"\n",
    "    f\" --buffer-size {BUFFER_SIZE}\"\n",
    "    f\" --save-dir {SAVE_DIR}\"\n",
    "    f\" --save-interval {SAVE_INTERVAL}\"\n",
    "    f\" --progress-interval 30\"\n",
    "    f\" --no-visualization\"\n",
    "    f\" --no-eval\"\n",
    "    f\" --device cuda\"\n",
    ")\n",
    "\n",
    "if RESUME_PATH:\n",
    "    cmd += f\" --resume {RESUME_PATH}\"\n",
    "\n",
    "print(\"Training command:\")\n",
    "print(cmd)\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Starting training...\")\n",
    "print(\"=\" * 60 + \"\\n\")\n",
    "\n",
    "!{cmd}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Results & Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Saved checkpoints on Google Drive:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if os.path.exists(SAVE_DIR):\n",
    "    for run_dir in sorted(os.listdir(SAVE_DIR)):\n",
    "        run_path = os.path.join(SAVE_DIR, run_dir)\n",
    "        if os.path.isdir(run_path):\n",
    "            files = os.listdir(run_path)\n",
    "            pt_files = sorted([f for f in files if f.endswith(\".pt\")])\n",
    "            print(f\"\\n  {run_dir}/\")\n",
    "            for f in pt_files:\n",
    "                size_mb = os.path.getsize(os.path.join(run_path, f)) / (1024 * 1024)\n",
    "                print(f\"    {f}  ({size_mb:.1f} MB)\")\n",
    "\n",
    "            # Show training metrics if available\n",
    "            metrics_path = os.path.join(run_path, \"training_metrics.json\")\n",
    "            if os.path.exists(metrics_path):\n",
    "                with open(metrics_path) as mf:\n",
    "                    metrics = json.load(mf)\n",
    "                n_iters = len(metrics)\n",
    "                if n_iters > 0:\n",
    "                    last = metrics[-1]\n",
    "                    print(f\"    Iterations completed: {n_iters}\")\n",
    "                    print(f\"    Final loss: {last.get('total_loss', 'N/A')}\")\n",
    "else:\n",
    "    print(\"  No checkpoints found.\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"To resume training in a new session:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"  1. Run cells 1-5 again\")\n",
    "print(f\"  2. Set RESUME_PATH to the run directory, e.g.:\")\n",
    "print(f\"     RESUME_PATH = \\\"{SAVE_DIR}/<run_directory>\\\"\")\n",
    "print(f\"  3. Run cell 6 to continue training\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}